{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.read_csv(\"./input/train.csv\")\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "datasets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \n",
       "Survived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \n",
       "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
       "SibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \n",
       "Parch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \n",
       "Fare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId  0.012658  \n",
       "Survived     0.257307  \n",
       "Pclass      -0.549500  \n",
       "Age          0.096067  \n",
       "SibSp        0.159651  \n",
       "Parch        0.216225  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = datasets.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles={\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Royalty\",\n",
    "    \"Don\":        \"Royalty\",\n",
    "    \"Sir\" :       \"Royalty\",\n",
    "    \"Dr\":         \"Officer\",\n",
    "    \"Rev\":        \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Dona\":       \"Royalty\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Royalty\"\n",
    "}\n",
    "\n",
    "def abstract_title(name):\n",
    "    return titles[name.split('.')[0].split(',')[1].strip()]\n",
    "\n",
    "def preprocessing(datasets):\n",
    "    datasets[\"Title\"] = datasets.Name.apply(abstract_title)\n",
    "    return datasets\n",
    "    \n",
    "# datasets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch     Fare\n",
       "0            1       3  22.0      1      0   7.2500\n",
       "1            2       1  38.0      1      0  71.2833\n",
       "2            3       3  26.0      0      0   7.9250\n",
       "3            4       1  35.0      1      0  53.1000\n",
       "4            5       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "drop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\n",
    "one_hot_attribs = [\"Sex\", \"Embarked\", \"Title\"]\n",
    "\n",
    "datasets = preprocessing(datasets.dropna(subset=[\"Sex\", \"Embarked\"]))\n",
    "# print(datasets.head())\n",
    "X_train_num = datasets.drop([\"Survived\"]+one_hot_attribs+drop_attribs, axis=1)\n",
    "y_train = datasets[\"Survived\"].copy()\n",
    "\n",
    "X_train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked Title  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q    Mr  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S   Mrs  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q    Mr  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S    Mr  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S   Mrs  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_test = preprocessing(pd.read_csv(\"./input/test.csv\"))\n",
    "\n",
    "datasets_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer as SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "])\n",
    "X_train_num_prepared = num_pipeline.fit_transform(X_train_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73250451,  0.82520863, -0.56367407,  0.43135024, -0.47432585,\n",
       "        -0.50023975],\n",
       "       [-1.72861124, -1.57221121,  0.66921696,  0.43135024, -0.47432585,\n",
       "         0.78894661],\n",
       "       [-1.72471797,  0.82520863, -0.25545131, -0.47519908, -0.47432585,\n",
       "        -0.48664993],\n",
       "       ...,\n",
       "       [ 1.72471797,  0.82520863, -0.10133993,  0.43135024,  2.00611934,\n",
       "        -0.17408416],\n",
       "       [ 1.72861124, -1.57221121, -0.25545131, -0.47519908, -0.47432585,\n",
       "        -0.0422126 ],\n",
       "       [ 1.73250451,  0.82520863,  0.20688282, -0.47519908, -0.47432585,\n",
       "        -0.49017322]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73250451,  0.82520863, -0.56367407, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.72861124, -1.57221121,  0.66921696, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.72471797,  0.82520863, -0.25545131, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.72471797,  0.82520863, -0.10133993, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.72861124, -1.57221121, -0.25545131, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.73250451,  0.82520863,  0.20688282, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from future_encoders import ColumnTransformer, OneHotEncoder\n",
    "\n",
    "num_attribs = list(X_train_num)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), one_hot_attribs),\n",
    "])\n",
    "\n",
    "# datasets[\"Embarked\"][datasets[\"Embarked\"].isnull()]\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(datasets)\n",
    "X_train_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79461279, 0.81756757, 0.81418919])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(rf_clf, X_train_prepared, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 17)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8323959505061868\n",
      "{'bootstrap': True, 'max_depth': 4, 'max_features': 6, 'n_estimators': 16534}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_estimators\": randint(low=5000, high=20000),\n",
    "    \"max_features\": randint(1, 11),\n",
    "    \"max_depth\": randint(1,5),\n",
    "    \"bootstrap\": [True, False],\n",
    "#     \"max_leaf_nodes\": randint(5,7),\n",
    "#     \"criterion\": [\"entropy\"],\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "rnd_search = RandomizedSearchCV(rf_clf, \n",
    "                               param_distributions=param_distribs,\n",
    "                               n_iter=20,\n",
    "                               cv=3,\n",
    "                               scoring=\"accuracy\",\n",
    "#                                 verbose=2,\n",
    "                               n_jobs=4)\n",
    "rnd_search.fit(X_train_prepared, y_train)\n",
    "\n",
    "print(rnd_search.best_score_)\n",
    "print(rnd_search.best_params_)\n",
    "final_model = rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7930258717660292 {'bootstrap': True, 'max_depth': 3, 'max_features': 1, 'n_estimators': 6126}\n",
      "0.8222722159730034 {'bootstrap': True, 'max_depth': 3, 'max_features': 10, 'n_estimators': 9432}\n",
      "0.8008998875140607 {'bootstrap': False, 'max_depth': 3, 'max_features': 2, 'n_estimators': 16128}\n",
      "0.7862767154105736 {'bootstrap': True, 'max_depth': 1, 'max_features': 4, 'n_estimators': 10897}\n",
      "0.7862767154105736 {'bootstrap': True, 'max_depth': 1, 'max_features': 3, 'n_estimators': 16935}\n",
      "0.8211473565804275 {'bootstrap': False, 'max_depth': 4, 'max_features': 3, 'n_estimators': 14043}\n",
      "0.8278965129358831 {'bootstrap': False, 'max_depth': 4, 'max_features': 10, 'n_estimators': 13343}\n",
      "0.7862767154105736 {'bootstrap': True, 'max_depth': 1, 'max_features': 7, 'n_estimators': 18485}\n",
      "0.7896512935883014 {'bootstrap': True, 'max_depth': 2, 'max_features': 4, 'n_estimators': 5677}\n",
      "0.8143982002249719 {'bootstrap': False, 'max_depth': 3, 'max_features': 7, 'n_estimators': 17577}\n",
      "0.7930258717660292 {'bootstrap': False, 'max_depth': 2, 'max_features': 8, 'n_estimators': 10052}\n",
      "0.7862767154105736 {'bootstrap': False, 'max_depth': 1, 'max_features': 8, 'n_estimators': 13988}\n",
      "0.7862767154105736 {'bootstrap': True, 'max_depth': 1, 'max_features': 10, 'n_estimators': 19790}\n",
      "0.8222722159730034 {'bootstrap': True, 'max_depth': 3, 'max_features': 10, 'n_estimators': 19442}\n",
      "0.8222722159730034 {'bootstrap': True, 'max_depth': 3, 'max_features': 10, 'n_estimators': 15877}\n",
      "0.7862767154105736 {'bootstrap': False, 'max_depth': 1, 'max_features': 5, 'n_estimators': 10627}\n",
      "0.8323959505061868 {'bootstrap': True, 'max_depth': 4, 'max_features': 6, 'n_estimators': 16534}\n",
      "0.8312710911136107 {'bootstrap': True, 'max_depth': 4, 'max_features': 6, 'n_estimators': 10348}\n",
      "0.8301462317210349 {'bootstrap': True, 'max_depth': 4, 'max_features': 6, 'n_estimators': 7155}\n",
      "0.8188976377952756 {'bootstrap': False, 'max_depth': 3, 'max_features': 5, 'n_estimators': 14031}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_test_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_test_score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8357705286839145\n",
      "{'C': 11.052225126586867, 'gamma': 0.02379365135307751, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from scipy.stats import reciprocal, expon\n",
    "\n",
    "param_distribs = {\n",
    "#     \"kernel\": [\"poly\"],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "#     \"kernel\": [\"linear\"],\n",
    "    \"C\": reciprocal(0.001, 1000),\n",
    "    \"gamma\": expon(scale=1.0),\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "rnd_search = RandomizedSearchCV(svc, \n",
    "                               param_distributions=param_distribs,\n",
    "                               n_iter=1000,\n",
    "                               cv=5,\n",
    "                               scoring=\"accuracy\",\n",
    "                               n_jobs=4,\n",
    "#                                verbose=2\n",
    "                               )\n",
    "rnd_search.fit(X_train_prepared, y_train)\n",
    "\n",
    "print(rnd_search.best_score_)\n",
    "print(rnd_search.best_params_)\n",
    "final_model = rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8256467941507312\n",
      "{'algorithm': 'brute', 'leaf_size': 27, 'n_neighbors': 9, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neighbors\": randint(3, 10),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"leaf_size\": randint(15, 45),\n",
    "    \n",
    "}\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "rnd_search = RandomizedSearchCV(knn_clf, \n",
    "                               param_distributions=param_distribs,\n",
    "                               n_iter=20,\n",
    "                               cv=5,\n",
    "                               scoring=\"accuracy\",\n",
    "#                                verbose=2,\n",
    "                               n_jobs=4)\n",
    "rnd_search.fit(X_train_prepared, y_train)\n",
    "\n",
    "print(rnd_search.best_score_)\n",
    "print(rnd_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8256467941507312\n",
      "{'max_iter': 496}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier()\n",
    "\n",
    "param_distribs = {\n",
    "    \"max_iter\": randint(1, 1001),\n",
    "#     \"weights\": [\"uniform\", \"distance\"],\n",
    "#     \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "#     \"leaf_size\": randint(15, 45),\n",
    "    \n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(sgd_clf, \n",
    "                               param_distributions=param_distribs,\n",
    "                               n_iter=20,\n",
    "                               cv=5,\n",
    "                               scoring=\"accuracy\",\n",
    "#                                verbose=2,\n",
    "                               n_jobs=4)\n",
    "rnd_search.fit(X_train_prepared, y_train)\n",
    "\n",
    "print(rnd_search.best_score_)\n",
    "print(rnd_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/runpy.py in _run_code(code=<code object <module> at 0x10c16bd20, file \"/usr...3.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/a.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10c16bd20, file \"/usr...3.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/a.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(15, 1)>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(15, 1)>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (15, 1)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=15, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 18, 6, 48, 15, 19654, tzinfo=tzutc()), 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'session': '64ff56d575c8474cb381e16b42a0a25a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'64ff56d575c8474cb381e16b42a0a25a']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 18, 6, 48, 15, 19654, tzinfo=tzutc()), 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'session': '64ff56d575c8474cb381e16b42a0a25a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'64ff56d575c8474cb381e16b42a0a25a'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 18, 6, 48, 15, 19654, tzinfo=tzutc()), 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'session': '64ff56d575c8474cb381e16b42a0a25a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>], cell_name='<ipython-input-291-f1ddc02be874>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1318b4208, execution_...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1311ca270, file \"<ipython-input-291-f1ddc02be874>\", line 26>\n        result = <ExecutionResult object at 1318b4208, execution_...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1311ca270, file \"<ipython-input-291-f1ddc02be874>\", line 26>, result=<ExecutionResult object at 1318b4208, execution_...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1311ca270, file \"<ipython-input-291-f1ddc02be874>\", line 26>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'ColumnTransformer': <class 'future_encoders.ColumnTransformer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt', 'datasets = pd.read_csv(\"./input/train.csv\")\\ndatasets.head()', 'datasets.describe()', 'datasets.info()', 'corr_matrix = datasets.corr()\\ncorr_matrix', 'from sklearn.preprocessing import SimpleImputer', 'from sklearn.impute import SimpleImputer', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...bs, axis=1)\\ny_train = datasets[\"Survived\"].copy()', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...atasets[\"Survived\"].copy()\\n\\nprint(X_train.head())', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...ain = datasets[\"Survived\"].copy()\\n\\nX_train.head()', 'y_train.head()', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'X_train_num_prepared.head()', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LinearSVR': <class 'sklearn.svm.classes.LinearSVR'>, 'OneHotEncoder': <class 'future_encoders.OneHotEncoder'>, 'Out': {2:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 3:        PassengerId    Survived      Pclass      ...000   31.000000  \nmax      6.000000  512.329200  , 5:              PassengerId  Survived    Pclass    ... \nParch        0.216225  \nFare         1.000000  , 15:    PassengerId  Pclass   Age  SibSp  Parch     F...           5       3  35.0      0      0   8.0500, 16: 0    0\n1    1\n2    1\n3    1\n4    0\nName: Survived, dtype: int64, 20: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 21:    PassengerId  Pclass   Age  SibSp  Parch     F...           5       3  35.0      0      0   8.0500, 23: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 27: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 28: array([[-1.73010796,  0.82737724, -0.56573646, .... -0.49237783,\n         0.        ,  1.        ]]), ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'ColumnTransformer': <class 'future_encoders.ColumnTransformer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt', 'datasets = pd.read_csv(\"./input/train.csv\")\\ndatasets.head()', 'datasets.describe()', 'datasets.info()', 'corr_matrix = datasets.corr()\\ncorr_matrix', 'from sklearn.preprocessing import SimpleImputer', 'from sklearn.impute import SimpleImputer', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...bs, axis=1)\\ny_train = datasets[\"Survived\"].copy()', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...atasets[\"Survived\"].copy()\\n\\nprint(X_train.head())', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...ain = datasets[\"Survived\"].copy()\\n\\nX_train.head()', 'y_train.head()', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'X_train_num_prepared.head()', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LinearSVR': <class 'sklearn.svm.classes.LinearSVR'>, 'OneHotEncoder': <class 'future_encoders.OneHotEncoder'>, 'Out': {2:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 3:        PassengerId    Survived      Pclass      ...000   31.000000  \nmax      6.000000  512.329200  , 5:              PassengerId  Survived    Pclass    ... \nParch        0.216225  \nFare         1.000000  , 15:    PassengerId  Pclass   Age  SibSp  Parch     F...           5       3  35.0      0      0   8.0500, 16: 0    0\n1    1\n2    1\n3    1\n4    0\nName: Survived, dtype: int64, 20: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 21:    PassengerId  Pclass   Age  SibSp  Parch     F...           5       3  35.0      0      0   8.0500, 23: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 27: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 28: array([[-1.73010796,  0.82737724, -0.56573646, .... -0.49237783,\n         0.        ,  1.        ]]), ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/Users/Billion/dev/codes/Kaggle/Titanic/<ipython-input-291-f1ddc02be874> in <module>()\n     21                                n_iter=10,\n     22                                cv=5,\n     23                                scoring=\"accuracy\",\n     24 #                                verbose=2,\n     25                                n_jobs=4)\n---> 26 rnd_search.fit(X_train_prepared, y_train)\n     27 \n     28 print(rnd_search.best_score_)\n     29 print(rnd_search.best_params_)\n     30 final_model = rnd_search.best_estimator_\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...rain_score='warn', scoring='accuracy', verbose=0), X=array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X = array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]])\n        y = 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Thu Apr 18 14:48:15 2019\nPID: 89756                    Python 3.7.0: /usr/local/anaconda3/bin/python\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, {'score': make_scorer(accuracy_score)}, array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), 0, {'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, {'score': make_scorer(accuracy_score)}, array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), 0, {'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, scorer={'score': make_scorer(accuracy_score)}, train=array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), verbose=0, parameters={'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=1.0, n_estimators=86, random_state=None)>\n        X_train = array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]])\n        y_train = 168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64, sample_weight=None)\n    408         # Check that algorithm is supported\n    409         if self.algorithm not in ('SAMME', 'SAMME.R'):\n    410             raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n    411 \n    412         # Fit\n--> 413         return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n        self.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=1.0, n_estimators=86, random_state=None)>\n        X = array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]])\n        y = 168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64\n        sample_weight = None\n    414 \n    415     def _validate_estimator(self):\n    416         \"\"\"Check the estimator and set the base_estimator_ attribute.\"\"\"\n    417         super(AdaBoostClassifier, self)._validate_estimator(\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]))\n    140             # Boosting step\n    141             sample_weight, estimator_weight, estimator_error = self._boost(\n    142                 iboost,\n    143                 X, y,\n    144                 sample_weight,\n--> 145                 random_state)\n        random_state = <mtrand.RandomState object>\n    146 \n    147             # Early termination\n    148             if sample_weight is None:\n    149                 break\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in _boost(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), iboost=0, X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]), random_state=<mtrand.RandomState object>)\n    472         if self.algorithm == 'SAMME.R':\n    473             return self._boost_real(iboost, X, y, sample_weight, random_state)\n    474 \n    475         else:  # elif self.algorithm == \"SAMME\":\n    476             return self._boost_discrete(iboost, X, y, sample_weight,\n--> 477                                         random_state)\n        random_state = <mtrand.RandomState object>\n    478 \n    479     def _boost_real(self, iboost, X, y, sample_weight, random_state):\n    480         \"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\n    481         estimator = self._make_estimator(random_state=random_state)\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in _boost_discrete(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), iboost=0, X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]), random_state=<mtrand.RandomState object>)\n    542 \n    543         y_predict = estimator.predict(X)\n    544 \n    545         if iboost == 0:\n    546             self.classes_ = getattr(estimator, 'classes_', None)\n--> 547             self.n_classes_ = len(self.classes_)\n        self.n_classes_ = undefined\n        self.classes_ = None\n    548 \n    549         # Instances incorrectly classified\n    550         incorrect = y_predict != y\n    551 \n\nTypeError: object of type 'NoneType' has no len()\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\", line 413, in fit\n    return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\", line 145, in fit\n    random_state)\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\", line 477, in _boost\n    random_state)\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\", line 547, in _boost_discrete\n    self.n_classes_ = len(self.classes_)\nTypeError: object of type 'NoneType' has no len()\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Thu Apr 18 14:48:15 2019\nPID: 89756                    Python 3.7.0: /usr/local/anaconda3/bin/python\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, {'score': make_scorer(accuracy_score)}, array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), 0, {'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, {'score': make_scorer(accuracy_score)}, array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), 0, {'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, scorer={'score': make_scorer(accuracy_score)}, train=array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), verbose=0, parameters={'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=1.0, n_estimators=86, random_state=None)>\n        X_train = array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]])\n        y_train = 168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64, sample_weight=None)\n    408         # Check that algorithm is supported\n    409         if self.algorithm not in ('SAMME', 'SAMME.R'):\n    410             raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n    411 \n    412         # Fit\n--> 413         return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n        self.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=1.0, n_estimators=86, random_state=None)>\n        X = array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]])\n        y = 168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64\n        sample_weight = None\n    414 \n    415     def _validate_estimator(self):\n    416         \"\"\"Check the estimator and set the base_estimator_ attribute.\"\"\"\n    417         super(AdaBoostClassifier, self)._validate_estimator(\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]))\n    140             # Boosting step\n    141             sample_weight, estimator_weight, estimator_error = self._boost(\n    142                 iboost,\n    143                 X, y,\n    144                 sample_weight,\n--> 145                 random_state)\n        random_state = <mtrand.RandomState object>\n    146 \n    147             # Early termination\n    148             if sample_weight is None:\n    149                 break\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in _boost(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), iboost=0, X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]), random_state=<mtrand.RandomState object>)\n    472         if self.algorithm == 'SAMME.R':\n    473             return self._boost_real(iboost, X, y, sample_weight, random_state)\n    474 \n    475         else:  # elif self.algorithm == \"SAMME\":\n    476             return self._boost_discrete(iboost, X, y, sample_weight,\n--> 477                                         random_state)\n        random_state = <mtrand.RandomState object>\n    478 \n    479     def _boost_real(self, iboost, X, y, sample_weight, random_state):\n    480         \"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\n    481         estimator = self._make_estimator(random_state=random_state)\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in _boost_discrete(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), iboost=0, X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]), random_state=<mtrand.RandomState object>)\n    542 \n    543         y_predict = estimator.predict(X)\n    544 \n    545         if iboost == 0:\n    546             self.classes_ = getattr(estimator, 'classes_', None)\n--> 547             self.n_classes_ = len(self.classes_)\n        self.n_classes_ = undefined\n        self.classes_ = None\n    548 \n    549         # Instances incorrectly classified\n    550         incorrect = y_predict != y\n    551 \n\nTypeError: object of type 'NoneType' has no len()\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Thu Apr 18 14:48:15 2019\nPID: 89756                    Python 3.7.0: /usr/local/anaconda3/bin/python\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, {'score': make_scorer(accuracy_score)}, array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), 0, {'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, {'score': make_scorer(accuracy_score)}, array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), 0, {'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, scorer={'score': make_scorer(accuracy_score)}, train=array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), verbose=0, parameters={'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=1.0, n_estimators=86, random_state=None)>\n        X_train = array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]])\n        y_train = 168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64, sample_weight=None)\n    408         # Check that algorithm is supported\n    409         if self.algorithm not in ('SAMME', 'SAMME.R'):\n    410             raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n    411 \n    412         # Fit\n--> 413         return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n        self.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=1.0, n_estimators=86, random_state=None)>\n        X = array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]])\n        y = 168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64\n        sample_weight = None\n    414 \n    415     def _validate_estimator(self):\n    416         \"\"\"Check the estimator and set the base_estimator_ attribute.\"\"\"\n    417         super(AdaBoostClassifier, self)._validate_estimator(\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]))\n    140             # Boosting step\n    141             sample_weight, estimator_weight, estimator_error = self._boost(\n    142                 iboost,\n    143                 X, y,\n    144                 sample_weight,\n--> 145                 random_state)\n        random_state = <mtrand.RandomState object>\n    146 \n    147             # Early termination\n    148             if sample_weight is None:\n    149                 break\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in _boost(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), iboost=0, X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]), random_state=<mtrand.RandomState object>)\n    472         if self.algorithm == 'SAMME.R':\n    473             return self._boost_real(iboost, X, y, sample_weight, random_state)\n    474 \n    475         else:  # elif self.algorithm == \"SAMME\":\n    476             return self._boost_discrete(iboost, X, y, sample_weight,\n--> 477                                         random_state)\n        random_state = <mtrand.RandomState object>\n    478 \n    479     def _boost_real(self, iboost, X, y, sample_weight, random_state):\n    480         \"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\n    481         estimator = self._make_estimator(random_state=random_state)\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in _boost_discrete(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), iboost=0, X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]), random_state=<mtrand.RandomState object>)\n    542 \n    543         y_predict = estimator.predict(X)\n    544 \n    545         if iboost == 0:\n    546             self.classes_ = getattr(estimator, 'classes_', None)\n--> 547             self.n_classes_ = len(self.classes_)\n        self.n_classes_ = undefined\n        self.classes_ = None\n    548 \n    549         # Instances incorrectly classified\n    550         incorrect = y_predict != y\n    551 \n\nTypeError: object of type 'NoneType' has no len()\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-291-f1ddc02be874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#                                verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                n_jobs=4)\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mrnd_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/runpy.py in _run_code(code=<code object <module> at 0x10c16bd20, file \"/usr...3.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/a.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10c16bd20, file \"/usr...3.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/a.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(15, 1)>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(15, 1)>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (15, 1)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=15, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 18, 6, 48, 15, 19654, tzinfo=tzutc()), 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'session': '64ff56d575c8474cb381e16b42a0a25a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'64ff56d575c8474cb381e16b42a0a25a']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 18, 6, 48, 15, 19654, tzinfo=tzutc()), 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'session': '64ff56d575c8474cb381e16b42a0a25a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'64ff56d575c8474cb381e16b42a0a25a'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 4, 18, 6, 48, 15, 19654, tzinfo=tzutc()), 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'session': '64ff56d575c8474cb381e16b42a0a25a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8678306cbd2e4442873c83d9be5586d0', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.ensemble import AdaBoostClassifier\\n...params_)\\nfinal_model = rnd_search.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>], cell_name='<ipython-input-291-f1ddc02be874>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1318b4208, execution_...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1311ca270, file \"<ipython-input-291-f1ddc02be874>\", line 26>\n        result = <ExecutionResult object at 1318b4208, execution_...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1311ca270, file \"<ipython-input-291-f1ddc02be874>\", line 26>, result=<ExecutionResult object at 1318b4208, execution_...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1311ca270, file \"<ipython-input-291-f1ddc02be874>\", line 26>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'ColumnTransformer': <class 'future_encoders.ColumnTransformer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt', 'datasets = pd.read_csv(\"./input/train.csv\")\\ndatasets.head()', 'datasets.describe()', 'datasets.info()', 'corr_matrix = datasets.corr()\\ncorr_matrix', 'from sklearn.preprocessing import SimpleImputer', 'from sklearn.impute import SimpleImputer', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...bs, axis=1)\\ny_train = datasets[\"Survived\"].copy()', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...atasets[\"Survived\"].copy()\\n\\nprint(X_train.head())', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...ain = datasets[\"Survived\"].copy()\\n\\nX_train.head()', 'y_train.head()', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'X_train_num_prepared.head()', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LinearSVR': <class 'sklearn.svm.classes.LinearSVR'>, 'OneHotEncoder': <class 'future_encoders.OneHotEncoder'>, 'Out': {2:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 3:        PassengerId    Survived      Pclass      ...000   31.000000  \nmax      6.000000  512.329200  , 5:              PassengerId  Survived    Pclass    ... \nParch        0.216225  \nFare         1.000000  , 15:    PassengerId  Pclass   Age  SibSp  Parch     F...           5       3  35.0      0      0   8.0500, 16: 0    0\n1    1\n2    1\n3    1\n4    0\nName: Survived, dtype: int64, 20: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 21:    PassengerId  Pclass   Age  SibSp  Parch     F...           5       3  35.0      0      0   8.0500, 23: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 27: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 28: array([[-1.73010796,  0.82737724, -0.56573646, .... -0.49237783,\n         0.        ,  1.        ]]), ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'ColumnTransformer': <class 'future_encoders.ColumnTransformer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt', 'datasets = pd.read_csv(\"./input/train.csv\")\\ndatasets.head()', 'datasets.describe()', 'datasets.info()', 'corr_matrix = datasets.corr()\\ncorr_matrix', 'from sklearn.preprocessing import SimpleImputer', 'from sklearn.impute import SimpleImputer', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...bs, axis=1)\\ny_train = datasets[\"Survived\"].copy()', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...atasets[\"Survived\"].copy()\\n\\nprint(X_train.head())', '\\ndrop_attribs = [\"Cabin\", \"Ticket\", \"Name\"]\\none_...ain = datasets[\"Survived\"].copy()\\n\\nX_train.head()', 'y_train.head()', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'from sklearn.preprocessing import Imputer as Sim...um_prepared = num_pipeline.fit_transform(X_train)', 'X_train_num_prepared.head()', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LinearSVR': <class 'sklearn.svm.classes.LinearSVR'>, 'OneHotEncoder': <class 'future_encoders.OneHotEncoder'>, 'Out': {2:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 3:        PassengerId    Survived      Pclass      ...000   31.000000  \nmax      6.000000  512.329200  , 5:              PassengerId  Survived    Pclass    ... \nParch        0.216225  \nFare         1.000000  , 15:    PassengerId  Pclass   Age  SibSp  Parch     F...           5       3  35.0      0      0   8.0500, 16: 0    0\n1    1\n2    1\n3    1\n4    0\nName: Survived, dtype: int64, 20: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 21:    PassengerId  Pclass   Age  SibSp  Parch     F...           5       3  35.0      0      0   8.0500, 23: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 27: array([[-1.73010796,  0.82737724, -0.56573646,  ... -0.4745452 , -0.47367361,\n        -0.49237783]]), 28: array([[-1.73010796,  0.82737724, -0.56573646, .... -0.49237783,\n         0.        ,  1.        ]]), ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/Users/Billion/dev/codes/Kaggle/Titanic/<ipython-input-291-f1ddc02be874> in <module>()\n     21                                n_iter=10,\n     22                                cv=5,\n     23                                scoring=\"accuracy\",\n     24 #                                verbose=2,\n     25                                n_jobs=4)\n---> 26 rnd_search.fit(X_train_prepared, y_train)\n     27 \n     28 print(rnd_search.best_score_)\n     29 print(rnd_search.best_params_)\n     30 final_model = rnd_search.best_estimator_\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...rain_score='warn', scoring='accuracy', verbose=0), X=array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X = array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]])\n        y = 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Thu Apr 18 14:48:15 2019\nPID: 89756                    Python 3.7.0: /usr/local/anaconda3/bin/python\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, {'score': make_scorer(accuracy_score)}, array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), 0, {'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, {'score': make_scorer(accuracy_score)}, array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), 0, {'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.73250451,  0.82520863, -0.56367407, ....  0.        ,\n         0.        ,  0.        ]]), y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 889, dtype: int64, scorer={'score': make_scorer(accuracy_score)}, train=array([167, 168, 169, 170, 172, 173, 174, 175, 1...    880, 881, 882, 883, 884, 885, 886, 887, 888]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    183, 185, 186, 189, 191, 192, 193, 194, 197]), verbose=0, parameters={'algorithm': 'SAMME', 'base_estimator': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,\n     random_state=None, tol=0.0001, verbose=0), 'n_estimators': 86}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=1.0, n_estimators=86, random_state=None)>\n        X_train = array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]])\n        y_train = 168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64, sample_weight=None)\n    408         # Check that algorithm is supported\n    409         if self.algorithm not in ('SAMME', 'SAMME.R'):\n    410             raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n    411 \n    412         # Fit\n--> 413         return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n        self.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=1.0, n_estimators=86, random_state=None)>\n        X = array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]])\n        y = 168    0\n169    0\n170    0\n171    0\n173    0\n174...90    0\nName: Survived, Length: 711, dtype: int64\n        sample_weight = None\n    414 \n    415     def _validate_estimator(self):\n    416         \"\"\"Check the estimator and set the base_estimator_ attribute.\"\"\"\n    417         super(AdaBoostClassifier, self)._validate_estimator(\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]))\n    140             # Boosting step\n    141             sample_weight, estimator_weight, estimator_error = self._boost(\n    142                 iboost,\n    143                 X, y,\n    144                 sample_weight,\n--> 145                 random_state)\n        random_state = <mtrand.RandomState object>\n    146 \n    147             # Early termination\n    148             if sample_weight is None:\n    149                 break\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in _boost(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), iboost=0, X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]), random_state=<mtrand.RandomState object>)\n    472         if self.algorithm == 'SAMME.R':\n    473             return self._boost_real(iboost, X, y, sample_weight, random_state)\n    474 \n    475         else:  # elif self.algorithm == \"SAMME\":\n    476             return self._boost_discrete(iboost, X, y, sample_weight,\n--> 477                                         random_state)\n        random_state = <mtrand.RandomState object>\n    478 \n    479     def _boost_real(self, iboost, X, y, sample_weight, random_state):\n    480         \"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\n    481         estimator = self._make_estimator(random_state=random_state)\n\n...........................................................................\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py in _boost_discrete(self=AdaBoostClassifier(algorithm='SAMME',\n          ...ing_rate=1.0, n_estimators=86, random_state=None), iboost=0, X=array([[-1.07843539, -1.57221121, -0.10133993, ....  0.        ,\n         0.        ,  0.        ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0]), sample_weight=array([0.00140647, 0.00140647, 0.00140647, 0.001...0647, 0.00140647, 0.00140647,\n       0.00140647]), random_state=<mtrand.RandomState object>)\n    542 \n    543         y_predict = estimator.predict(X)\n    544 \n    545         if iboost == 0:\n    546             self.classes_ = getattr(estimator, 'classes_', None)\n--> 547             self.n_classes_ = len(self.classes_)\n        self.n_classes_ = undefined\n        self.classes_ = None\n    548 \n    549         # Instances incorrectly classified\n    550         incorrect = y_predict != y\n    551 \n\nTypeError: object of type 'NoneType' has no len()\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "ab_clf = AdaBoostClassifier()\n",
    "# cross_val_score(ab_clf, X_train_prepared, y_train, scoring=\"accuracy\", cv=3)\n",
    "\n",
    "param_distribs = {\n",
    "#     \"learning_rate\": randint(0.01, 1000),\n",
    "    \"n_estimators\": randint(10, 100),\n",
    "#     \"algorithm\": [\"SAMME\"],\n",
    "    \"base_estimator\": [\n",
    "#         DecisionTreeClassifier(max_depth=depth) for depth in range(1, 100),\n",
    "        LinearSVC(),\n",
    "    ],\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(ab_clf, \n",
    "                               param_distributions=param_distribs,\n",
    "                               n_iter=10,\n",
    "                               cv=5,\n",
    "                               scoring=\"accuracy\",\n",
    "#                                verbose=2,\n",
    "                               n_jobs=4)\n",
    "rnd_search.fit(X_train_prepared, y_train)\n",
    "\n",
    "print(rnd_search.best_score_)\n",
    "print(rnd_search.best_params_)\n",
    "final_model = rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepared = full_pipeline.transform(datasets_test)\n",
    "y_test_pred = final_model.predict(X_test_prepared)\n",
    "\n",
    "datasets_test[\"Survived\"] = y_test_pred\n",
    "# datasets_test.head()\n",
    "test_predictions = datasets_test.loc[:, [\"PassengerId\", \"Survived\"]]\n",
    "# test_predictions.head()\n",
    "# import os\n",
    "# os.mkdir(\"./output\")\n",
    "test_predictions.to_csv(\"./output/titanic_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
